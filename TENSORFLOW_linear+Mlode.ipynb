{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\umarv\\\\AppData\\\\Local\\\\Temp\\\\tmp58m34f_w',\n",
       " <http.client.HTTPMessage at 0x1ed0ed2a978>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fetching data from website\n",
    "\n",
    "import tempfile\n",
    "import urllib.request\n",
    "train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", train_file.name)\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## reading file into csv format\n",
    "\n",
    "import pandas as pd\n",
    "CSV_COLUMNS = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "    \"income_bracket\"]\n",
    "df_train = pd.read_csv(train_file.name, names=CSV_COLUMNS, skipinitialspace=True)\n",
    "df_test = pd.read_csv(test_file.name, names=CSV_COLUMNS, skipinitialspace=True, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "0          2174             0              40  United-States          <=50K  \n",
       "1             0             0              13  United-States          <=50K  \n",
       "2             0             0              40  United-States          <=50K  \n",
       "3             0             0              40  United-States          <=50K  \n",
       "4             0             0              40           Cuba          <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll construct a label column named \"label\"(target variable) whose value is 1 if the income is over 50K, and 0 otherwise.\n",
    "\n",
    "train_labels = (df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "test_labels = (df_test[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converting Data into Tensors\n",
    "\n",
    "##When building a tf.estimator model, the input data is specified by means of an Input Builder function\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle):\n",
    "  \"\"\"Input builder function.\"\"\"\n",
    "  df_data = pd.read_csv(\n",
    "      tf.gfile.Open(data_file),\n",
    "      names=CSV_COLUMNS,\n",
    "      skipinitialspace=True,\n",
    "      engine=\"python\",\n",
    "      skiprows=1)\n",
    "  # remove NaN elements\n",
    "  df_data = df_data.dropna(how=\"any\", axis=0)\n",
    "  labels = df_data[\"income_bracket\"].apply(lambda x: \">50K\" in x).astype(int)\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=df_data,\n",
    "      y=labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle,\n",
    "      num_threads=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Selecting and Engineering Features for the Model\n",
    "\n",
    "# Base Categorical Feature Columns\n",
    "# converting categorical feature into facter variables \n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"gender\", [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"occupation\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"marital_status\", [\n",
    "        \"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n",
    "        \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"\n",
    "    ])\n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"relationship\", [\n",
    "        \"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n",
    "        \"Other-relative\"\n",
    "    ])\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"workclass\", [\n",
    "        \"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n",
    "        \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"\n",
    "    ])\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"native_country\", hash_bucket_size=1000)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"race\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing base continuos feature\n",
    "\n",
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making Continuous Features Categorical through Bucketization\n",
    "\n",
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Intersecting Multiple Columns with CrossedColumn\n",
    "\n",
    "education_x_occupation = tf.feature_column.crossed_column(\n",
    "    [\"education\", \"occupation\"], hash_bucket_size=1000)\n",
    "\n",
    "age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(\n",
    "    [age_buckets, \"education\", \"occupation\"], hash_bucket_size=1000)\n",
    "age_buckets_x_race_x_occupation = tf.feature_column.crossed_column(\n",
    "    [age_buckets, \"race\", \"occupation\"], hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\umarv\\\\AppData\\\\Local\\\\Temp\\\\tmphj9rygdq', '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "# now data has been prepared for traing model on them\n",
    "## After processing the input data and defining all the feature columns, we're now ready to put them all together and build a Logistic Regression model.\n",
    "## Defining The Logistic Regression Model\n",
    "base_columns = [\n",
    "    gender, native_country, education, occupation, workclass, relationship,\n",
    "    age_buckets,\n",
    "]\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(\n",
    "        [\"education\", \"occupation\"], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [age_buckets, \"education\", \"occupation\"], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [\"native_country\", \"occupation\"], hash_bucket_size=1000)\n",
    "]\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir, feature_columns=base_columns + crossed_columns)\n",
    "## The learned model files will be stored in model_dir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt-2150\n",
      "INFO:tensorflow:Saving checkpoints for 2151 into C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt.\n",
      "INFO:tensorflow:loss = 40.6828, step = 2151\n",
      "INFO:tensorflow:global_step/sec: 114.002\n",
      "INFO:tensorflow:loss = 36.2864, step = 2251 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.964\n",
      "INFO:tensorflow:loss = 27.2409, step = 2351 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.334\n",
      "INFO:tensorflow:loss = 35.3101, step = 2451 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.457\n",
      "INFO:tensorflow:loss = 36.0771, step = 2551 (0.745 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2650 into C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 37.1017.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x1ed0fd3b780>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training and Evaluating Our Model\n",
    "## Training a model is just a one-liner using the tf.estimator API:\n",
    "# set num_epochs to None to get infinite stream of data.\n",
    "m.train(\n",
    "    input_fn=input_fn(train_file.name, num_epochs=None, shuffle=True),\n",
    "    steps=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-29-14:19:46\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt-2650\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-29-14:19:54\n",
      "INFO:tensorflow:Saving dict for global step 2650: accuracy = 0.834224, accuracy_baseline = 0.763774, auc = 0.881216, auc_precision_recall = 0.692679, average_loss = 0.355393, global_step = 2650, label/mean = 0.236226, loss = 35.4978, prediction/mean = 0.239685\n",
      "model directory = C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\n",
      "accuracy: 0.834224\n",
      "accuracy_baseline: 0.763774\n",
      "auc: 0.881216\n",
      "auc_precision_recall: 0.692679\n",
      "average_loss: 0.355393\n",
      "global_step: 2650\n",
      "label/mean: 0.236226\n",
      "loss: 35.4978\n",
      "prediction/mean: 0.239685\n"
     ]
    }
   ],
   "source": [
    "results = m.evaluate(\n",
    "    input_fn=input_fn(test_file.name, num_epochs=1, shuffle=False),\n",
    "    steps=None)\n",
    "print(\"model directory = %s\" % model_dir)\n",
    "for key in sorted(results):\n",
    "  print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\umarv\\\\AppData\\\\Local\\\\Temp\\\\tmphj9rygdq', '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "## regularization to avoid overfitting\n",
    "\n",
    "\n",
    "m = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir, feature_columns=base_columns + crossed_columns,\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=1.90,\n",
    "      l2_regularization_strength=1.90)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt-7050\n",
      "INFO:tensorflow:Saving checkpoints for 7051 into C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt.\n",
      "INFO:tensorflow:loss = 37.8441, step = 7051\n",
      "INFO:tensorflow:global_step/sec: 118.882\n",
      "INFO:tensorflow:loss = 22.6692, step = 7151 (0.844 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7250 into C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 31.2684.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x1ed2244b9b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## training the regularized model model\n",
    "m.train(\n",
    "    input_fn=input_fn(train_file.name, num_epochs=None, shuffle=True),\n",
    "    steps=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-29-14:51:55\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\\model.ckpt-7250\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-29-14:52:04\n",
      "INFO:tensorflow:Saving dict for global step 7250: accuracy = 0.835207, accuracy_baseline = 0.763774, auc = 0.883041, auc_precision_recall = 0.695703, average_loss = 0.351953, global_step = 7250, label/mean = 0.236226, loss = 35.1543, prediction/mean = 0.238741\n",
      "model directory = C:\\Users\\umarv\\AppData\\Local\\Temp\\tmphj9rygdq\n",
      "accuracy: 0.835207\n",
      "accuracy_baseline: 0.763774\n",
      "auc: 0.883041\n",
      "auc_precision_recall: 0.695703\n",
      "average_loss: 0.351953\n",
      "global_step: 7250\n",
      "label/mean: 0.236226\n",
      "loss: 35.1543\n",
      "prediction/mean: 0.238741\n"
     ]
    }
   ],
   "source": [
    "## cheking the prediction of regularised model on test data\n",
    "\n",
    "results = m.evaluate(\n",
    "    input_fn=input_fn(test_file.name, num_epochs=1, shuffle=False),\n",
    "    steps=None)\n",
    "print(\"model directory = %s\" % model_dir)\n",
    "for key in sorted(results):\n",
    "  print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Wide and deep learning\n",
    "\n",
    "# ALL categorical columns are converted into embedding column to reduce the dimensions of sparse column,\n",
    "# Then they are concatinated with cotinous columns\n",
    "\n",
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(workclass),\n",
    "    tf.feature_column.indicator_column(education),\n",
    "    tf.feature_column.indicator_column(gender),\n",
    "    tf.feature_column.indicator_column(relationship),\n",
    "    # To show an example of embedding\n",
    "    tf.feature_column.embedding_column(native_country, dimension=8),\n",
    "    tf.feature_column.embedding_column(occupation, dimension=8),\n",
    "    age,\n",
    "    education_num,\n",
    "    capital_gain,\n",
    "    capital_loss,\n",
    "    hours_per_week,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\umarv\\\\AppData\\\\Local\\\\Temp\\\\tmp5i2zco74', '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dir_nn = tempfile.mkdtemp()\n",
    "m = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=model_dir_nn,\n",
    "    linear_feature_columns=crossed_columns,\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=[100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\umarv\\AppData\\Local\\Temp\\tmp5i2zco74\\model.ckpt-1300\n",
      "INFO:tensorflow:Saving checkpoints for 1301 into C:\\Users\\umarv\\AppData\\Local\\Temp\\tmp5i2zco74\\model.ckpt.\n",
      "INFO:tensorflow:loss = 46.7423, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 112.272\n",
      "INFO:tensorflow:loss = 40.5235, step = 1401 (0.892 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into C:\\Users\\umarv\\AppData\\Local\\Temp\\tmp5i2zco74\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 36.7199.\n",
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=False and num_threads > 1. This will create multiple threads, all reading the array/dataframe in order. If you want examples read in order, use one thread; if you want multiple threads, enable shuffling.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-29-15:11:00\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\umarv\\AppData\\Local\\Temp\\tmp5i2zco74\\model.ckpt-1500\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-29-15:11:09\n",
      "INFO:tensorflow:Saving dict for global step 1500: accuracy = 0.819913, accuracy_baseline = 0.763774, auc = 0.85032, auc_precision_recall = 0.677864, average_loss = 0.409404, global_step = 1500, label/mean = 0.236226, loss = 40.8927, prediction/mean = 0.233906\n",
      "model directory = C:\\Users\\umarv\\AppData\\Local\\Temp\\tmp5i2zco74\n",
      "accuracy: 0.819913\n",
      "accuracy_baseline: 0.763774\n",
      "auc: 0.85032\n",
      "auc_precision_recall: 0.677864\n",
      "average_loss: 0.409404\n",
      "global_step: 1500\n",
      "label/mean: 0.236226\n",
      "loss: 40.8927\n",
      "prediction/mean: 0.233906\n"
     ]
    }
   ],
   "source": [
    "# After reading in the data, you can train and evaluate the model:\n",
    "\n",
    "# set num_epochs to None to get infinite stream of data.\n",
    "m.train(\n",
    "    input_fn=input_fn(train_file.name, num_epochs=None, shuffle=True),\n",
    "    steps=200)\n",
    "# set steps to None to run evaluation until all data consumed.\n",
    "results = m.evaluate(\n",
    "    input_fn=input_fn(test_file.name, num_epochs=1, shuffle=False),\n",
    "    steps=None)\n",
    "print(\"model directory = %s\" % model_dir_nn)\n",
    "for key in sorted(results):\n",
    "  print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
